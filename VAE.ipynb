{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5668147153904e3d8c8da33c2b9d43b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a441f9a80c204f26a0261b3118d1741a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9562666a8f8c41a89f0202f3accf73a5",
              "IPY_MODEL_7b11c5a490a74a81bf6edc2a07f53fa8"
            ]
          }
        },
        "a441f9a80c204f26a0261b3118d1741a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9562666a8f8c41a89f0202f3accf73a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf9409d38aa54f5a88c64e849aa8c18f",
            "_dom_classes": [],
            "description": "epochs: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 15,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 15,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da1e4780f4db44f59e92a2a41064c564"
          }
        },
        "7b11c5a490a74a81bf6edc2a07f53fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ca884d1db9c48fc9f1dfb922de0ada5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15/15 [01:28&lt;00:00,  5.92s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d64c05b4c0e640649b0b67f717c0cd30"
          }
        },
        "cf9409d38aa54f5a88c64e849aa8c18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da1e4780f4db44f59e92a2a41064c564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ca884d1db9c48fc9f1dfb922de0ada5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d64c05b4c0e640649b0b67f717c0cd30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thijsgelton/P9-Group7_VariationalAutoEncoder/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87t9m7vdFL6G"
      },
      "source": [
        "```\n",
        "SOW-MKI95 Computer Graphics & Computer Vision Spring\n",
        "Variational autoencoders practical\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTiJBPQyFPOk"
      },
      "source": [
        "```\n",
        "Group number: 7\n",
        "Student 1 name/number: Marit Hagens, s4808061\n",
        "Student 2 name/number: Joost Verhaert, s1047220\n",
        "Student 3 name/number: Thijs Gelton, s4480783\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIinhT5oTfxT",
        "outputId": "f788d642-a234-460f-baea-5d45d99fe5f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/09/a13d45136ce70589cceee4081f485f8f47fc5eb716d07981d4c2547763df/mxnet_cu100-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (352.6MB)\n",
            "\u001b[K     |████████████████████████████████| 352.6MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet-cu100\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu100-1.8.0.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSl_faq2EGYd"
      },
      "source": [
        "from mxnet import nd, gluon\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.contrib.estimator import estimator\n",
        "from mxnet.gluon.contrib.estimator.event_handler import TrainBegin, TrainEnd, EpochEnd, CheckpointHandler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import mxnet as mx\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Feel free to import other modules/packages"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE2TFzekUq8s",
        "outputId": "a5d83dbe-0bb0-40c5-ad91-cd88bc56aa4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def gpu_device(gpu_number=0):\n",
        "    try:\n",
        "        _ = mx.nd.array([1, 2, 3], ctx=mx.gpu(gpu_number))\n",
        "    except mx.MXNetError:\n",
        "        return None\n",
        "    return mx.gpu(gpu_number)\n",
        "\n",
        "gpu = gpu_device()\n",
        "\n",
        "if gpu:\n",
        "    print('Using GPU for model_ctx')\n",
        "    model_ctx = gpu\n",
        "else:\n",
        "    print('Using CPU for model_ctx')\n",
        "    model_ctx = mx.cpu()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU for model_ctx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy8kd5Vvdt7P"
      },
      "source": [
        "## Loading in the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5CstDKudrS5"
      },
      "source": [
        "# Fixing the random seed\n",
        "mx.random.seed(42)\n",
        "\n",
        "# Get data\n",
        "mnist = mx.test_utils.get_mnist()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBxiJAKXiVwJ"
      },
      "source": [
        "# Create data iterators\n",
        "batch_size = 100\n",
        "train_data = mx.io.NDArrayIter(mnist['train_data'].reshape(-1, 784), mnist['train_label'], batch_size, shuffle=True)\n",
        "val_data = mx.io.NDArrayIter(mnist['test_data'].reshape(-1, 784), mnist['test_label'], batch_size)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izULJfhWEGYg"
      },
      "source": [
        "### Task 1 (10 points):\n",
        "\n",
        "* Implement the decoder class for a variational autoencoder.\n",
        "\n",
        "---o---\n",
        "\n",
        "Recall that the decoder transforms latents (features) to observables (images). It corresponds to p(x | z) in the context of variational inference (and the slides), where x is observables and z is latents. Note that it should output the Gaussian parameters (mean and variance per pixel) of images rather than images themselves.\n",
        "\n",
        "---o---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEDrnNpjEGYh"
      },
      "source": [
        "class Decoder(nn.HybridSequential):\n",
        "    def __init__(self, activation = \"relu\", hiddens = 400, observables = 784, layers = 1, **kwargs): # Feel free to use different arguments\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        for i in range(layers):\n",
        "            self.add(nn.Dense(hiddens, activation=activation))\n",
        "        self.add(nn.Dense(observables*2, activation=\"sigmoid\"))       \n",
        "        "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KE1zoq2EGYk"
      },
      "source": [
        "### Task 2 (10 points):\n",
        "\n",
        "* Implement the encoder class for a variational autoencoder.\n",
        "\n",
        "---o---\n",
        "\n",
        "Recall that the encoder transforms observables (images) to latents (features). It corresponds to q(z | x) in the context of variational inference (and the slides), where z is latents and x is observables. Note that it should output the Gaussian parameters (mean and variance per feature) of features rather than features themselves.\n",
        "\n",
        "---o---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sZngO1pEGYl"
      },
      "source": [
        "class Encoder(nn.HybridSequential):\n",
        "    def __init__(self, activation = \"relu\", hiddens= 400, latents = 2, layers = 1, **kwargs): # Feel free to use different arguments\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        for i in range(layers):\n",
        "            self.add(nn.Dense(hiddens, activation=activation))\n",
        "        self.add(nn.Dense(latents * 2)) # No activation function, because mean and std can be [-inf, +inf]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N59f0FCOEGYn"
      },
      "source": [
        "### Task:\n",
        "\n",
        "* Implement the loss function class for a variational autoecoder.\n",
        "\n",
        "---o---\n",
        "\n",
        "The loss function takes the following arguments as input:\n",
        "\n",
        "* x        : input images (mini batch)\n",
        "* x_mean   : mean of the decoded images (output of the decoder)\n",
        "* x_log_var: mean of the decoded images (output of the decoder)\n",
        "* z_mean   : mean of the encoded features (output of the encoder)\n",
        "* z_log_var: log variance of the encoded features (output of the encoder)\n",
        "\n",
        "It gives the following evidence lower bound (ELBO) as ouput:\n",
        "\n",
        "* $L = D_{KL}(q(z | x), p(z)) -  E_{z\\sim q}[log p(x | z)]$\n",
        "\n",
        "where\n",
        "\n",
        "* The first term is the KL divergence between the approximate Gaussian posterior (q) and the standard Gaussian prior (p), which can be interpreted as a form of regularization.\n",
        "* The second term is the Gaussian negative log likelihood, which is the term that fits the data and is very similar to the usual loss functions that are usded in deep learning.\n",
        "\n",
        "---o---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAfVRFXJEGYo"
      },
      "source": [
        "class Lossfun:\n",
        "    def __init__(self, w = 1.0): # Feel free to use different w which can be used as the weight of the different loss components\n",
        "        self.w = w\n",
        "\n",
        "    def __call__(self, x, x_mean, x_log_var, z_mean, z_log_var):\n",
        "        return self.w * self.get_kl(z_mean, z_log_var) + (1 - self.w) * self.get_nll(x, x_mean, x_log_var)\n",
        "\n",
        "    def get_kl(self, z_mean, z_log_var):\n",
        "        return 0.5 * nd.mean(((z_mean ** 2) + nd.exp(z_log_var) - z_log_var - 1))\n",
        "\n",
        "    def get_nll(self, x, x_mean, x_log_var):\n",
        "        return 0.5 * nd.mean(((x_log_var + math.log(2 * math.pi)) + ((x - x_mean) ** 2) * nd.exp(-x_log_var)))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gxKE99gEGYr"
      },
      "source": [
        "### Task (5 points):\n",
        "\n",
        "* Implement the variational autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esbwnvO4EGYr"
      },
      "source": [
        "class VariationalAutoencoder(gluon.HybridBlock):\n",
        "    def __init__(self,  activation = \"relu\", hiddens= 400, latents = 2, observables = 784, layers = 1, **kwargs): # Feel free to use different arguments\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.latents = latents\n",
        "        with self.name_scope():\n",
        "            self.encoder = Encoder(activation, hiddens, latents, layers, **kwargs)\n",
        "            self.decoder = Decoder(activation, hiddens, observables, layers, **kwargs)\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        mean_lv = self.encoder(x)        \n",
        "        z_mean, z_log_var = F.split(mean_lv, axis=1, num_outputs=2)\n",
        "        eps = F.random_normal(loc=0, scale=1, shape=(x.shape[0], self.latents), ctx=model_ctx) # Reparamitisation trick\n",
        "        z = z_mean + F.exp(0.5 * z_log_var) * eps\n",
        "        x_mean, x_log_var = F.split(self.decoder(z), axis=1, num_outputs=2)\n",
        "        return x, x_mean, x_log_var, z_mean, z_log_var"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjFitH3uEGYu"
      },
      "source": [
        "### Task (25 points):\n",
        "\n",
        "* Train the variational autoencoder on the Mnist dataset. You can refer to the previous assignment to implement your training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEW5GJ3AkOj7"
      },
      "source": [
        "# check wheter there is a gpu and use the best option\n",
        "gpus = mx.test_utils.list_gpus()\n",
        "ctx =  [mx.gpu()] if gpus else [mx.cpu(0), mx.cpu(1)]\n",
        "vae_model = VariationalAutoencoder()\n",
        "loss_fn = Lossfun()\n",
        "vae_model.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
        "trainer = gluon.Trainer(vae_model.collect_params(), 'adam', {'learning_rate': 0.001})"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ8bKzBjj4hc",
        "outputId": "d475e3e9-8510-4f1e-a64f-70c6a4572a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334,
          "referenced_widgets": [
            "5668147153904e3d8c8da33c2b9d43b4",
            "a441f9a80c204f26a0261b3118d1741a",
            "9562666a8f8c41a89f0202f3accf73a5",
            "7b11c5a490a74a81bf6edc2a07f53fa8",
            "cf9409d38aa54f5a88c64e849aa8c18f",
            "da1e4780f4db44f59e92a2a41064c564",
            "6ca884d1db9c48fc9f1dfb922de0ada5",
            "d64c05b4c0e640649b0b67f717c0cd30"
          ]
        }
      },
      "source": [
        "import time\n",
        "n_epoch = 50\n",
        "print_period = n_epoch // 10\n",
        "start = time.time()\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for i in tqdm(range(epoch), desc='epochs'):\n",
        "    # Reset the train data iterator.\n",
        "    epoch_loss = 0\n",
        "    epoch_val_loss = 0\n",
        "\n",
        "    train_data.reset()\n",
        "    val_data.reset()\n",
        "\n",
        "    n_batch_train = 0\n",
        "    # Loop over the train data iterator.\n",
        "    for batch in train_data:\n",
        "        n_batch_train +=1\n",
        "        # Splits train data into multiple slices along batch_axis\n",
        "        # and copy each slice into a context.\n",
        "        data = batch.data[0].as_in_context(model_ctx)\n",
        "        # Splits train labels into multiple slices along batch_axis\n",
        "        # and copy each slice into a context.\n",
        "        # label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
        "        outputs = []\n",
        "        # Inside training scope\n",
        "        with ag.record():\n",
        "            z = vae_model(data)\n",
        "            # Computes softmax cross entropy loss.\n",
        "            loss = loss_fn(*z)\n",
        "        loss.backward()\n",
        "        trainer.step(batch.data[0].shape[0])\n",
        "        epoch_loss += nd.mean(loss).asscalar()\n",
        "\n",
        "        # Backpropagate the error for one iteration.\n",
        "        outputs.append(z)\n",
        "\n",
        "    n_batch_val = 0\n",
        "    for batch in val_data:\n",
        "        n_batch_val +=1\n",
        "        data = batch.data[0].as_in_context(model_ctx)\n",
        "        z = vae_model(data)\n",
        "        loss = loss_fn(*z)\n",
        "        epoch_val_loss += nd.mean(loss).asscalar()\n",
        "\n",
        "    epoch_loss /= n_batch_train\n",
        "    epoch_val_loss /= n_batch_val\n",
        "\n",
        "    training_loss.append(epoch_loss)\n",
        "    validation_loss.append(epoch_val_loss)\n",
        "\n",
        "    if epoch % max(print_period,1) == 0:\n",
        "        tqdm.write('Epoch{}, Training loss {}, Validation loss {}'.format(i, epoch_loss, epoch_val_loss))\n",
        "\n",
        "end = time.time()\n",
        "print('Time elapsed: {:.2f}s'.format(end - start))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5668147153904e3d8c8da33c2b9d43b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='epochs', max=15.0, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch0, Training loss 0.008620143343384068, Validation loss 0.008491959501989187\n",
            "Epoch1, Training loss 0.008508590940230836, Validation loss 0.008380772797390818\n",
            "Epoch2, Training loss 0.00840166543610394, Validation loss 0.008274451214820146\n",
            "Epoch3, Training loss 0.008299013155046851, Validation loss 0.008172165923751891\n",
            "Epoch4, Training loss 0.008200328665940712, Validation loss 0.008073826245963573\n",
            "Epoch5, Training loss 0.008105422820275028, Validation loss 0.007979395757429302\n",
            "Epoch6, Training loss 0.008014123514294624, Validation loss 0.007888562879525125\n",
            "Epoch7, Training loss 0.007926052202625822, Validation loss 0.0078013562224805355\n",
            "Epoch8, Training loss 0.007841180966546138, Validation loss 0.007716846782714128\n",
            "Epoch9, Training loss 0.007759181635143856, Validation loss 0.0076354967849329115\n",
            "Epoch10, Training loss 0.007680049220410486, Validation loss 0.007556818425655365\n",
            "Epoch11, Training loss 0.0076035034283995625, Validation loss 0.0074807544331997634\n",
            "Epoch12, Training loss 0.007529471172795941, Validation loss 0.007407482964918017\n",
            "Epoch13, Training loss 0.0074578192418751615, Validation loss 0.007336364001967013\n",
            "Epoch14, Training loss 0.007388342300740381, Validation loss 0.007267715204507113\n",
            "\n",
            "Time elapsed: 88.86s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4gKefJpnzB6",
        "outputId": "38560940-f917-4fa7-9cd2-a6f1ec15488b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(mnist[\"test_data\"][0, 0], cmap='gray')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f65d56812d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3i-32h8oleP"
      },
      "source": [
        "x, x_mean, x_log_var, z_mean, z_log_var = vae_model(nd.array(mnist[\"test_data\"][0, 0].reshape(1, 784)).as_in_context(model_ctx))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI940QMopAvL",
        "outputId": "8f8332a5-1d36-4647-fcc9-4262e684f4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(x_mean[0].asnumpy().reshape(28, 28), cmap='gray')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f65d4607950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er_NwFS0EGYy"
      },
      "source": [
        "### Task (50 points):\n",
        "* Evaluate the reconstruction quality of the variational autoencoder: Draw some Mnist like images, encode them, decode them, visualize them and briefly explain the results.\n",
        " * Repeat the task with drawings of something else (e.g., a face).\n",
        "* Evaluate the sampling quality of the variational autoencoder: Sample some random features from the prior, decode them, visualize them and briefly explain the results.\n",
        " * Repeat the task with features on a regular grid.\n",
        "* Evaluate the latent quality of the variational autoencoder: Scatter plot features of images, color code their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1SGUbpfEGYy"
      },
      "source": [
        "# Your code here..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}